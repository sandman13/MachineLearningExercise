1、KNN算法可以完成很多分类任务，但是它最大的缺点就是无法给出数据的内在含义，决策树的优势在于数据形式非常容易理解。

2、决策树在准备数据时，只适用于标称型数据，因此数值型数据必须离散化。

3、熵越高，则混合的数据越多。得到熵之后，就可以按照获取最大增益的方法划分数据集。

4、append()和extend()方法的不同
a=[1,2,3]
b=[4,5,6]
a.append(b)    #a=[1,2,3,[4,5,6]]
a.extend(b)    #a=[1,2,3,4,5,6]

5、决策树工作原理：（1）得到原始数据集，然后基于最好的特征划分数据集；（2）由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分；（3）第一次划分之后，数据将被向下传递到数分支的下一个节点，在这个节点上，可以再次划分数据。
采用递归实现：递归的结束条件是程序遍历完所有划分数据集的属性或者每个分支下的所有实例都具有相同的分类。
